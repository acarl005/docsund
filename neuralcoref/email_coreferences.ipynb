{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Coreference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x22fb74aae80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import os, sys, email, re\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "import pkg_resources\n",
    "pkg_resources.require('SpaCy==2.1.0')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import neuralcoref\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add neural coref to SpaCy's pipe\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517401, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a DataFrame\n",
    "emails_df = pd.read_csv('emails.csv')\n",
    "print(emails_df.shape)\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "def get_text_from_email(msg):\n",
    "    '''To get the content from email objects'''\n",
    "    parts = []\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            parts.append( part.get_payload() )\n",
    "    return ''.join(parts)\n",
    "\n",
    "def split_email_addresses(line):\n",
    "    '''To separate multiple email addresses'''\n",
    "    if line:\n",
    "        addrs = line.split(',')\n",
    "        addrs = frozenset(map(lambda x: x.strip(), addrs))\n",
    "    else:\n",
    "        addrs = None\n",
    "    return addrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Mime-Version</th>\n",
       "      <th>Content-Type</th>\n",
       "      <th>Content-Transfer-Encoding</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-Origin</th>\n",
       "      <th>X-FileName</th>\n",
       "      <th>content</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>&lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(tim.belden@enron.com)</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen (Non-Privileged).pst</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>&lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(john.lavorato@enron.com)</td>\n",
       "      <td>Re:</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>John J Lavorato &lt;John J Lavorato/ENRON@enronXg...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen (Non-Privileged).pst</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>&lt;24216240.1075855687451.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(leah.arsdall@enron.com)</td>\n",
       "      <td>Re: test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Leah Van Arsdall</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen.nsf</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>&lt;13505866.1075863688222.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(randall.gay@enron.com)</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Randall L Gay</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen.nsf</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>&lt;30922949.1075863688243.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(greg.piper@enron.com)</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Greg Piper</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen.nsf</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                     Message-ID  \\\n",
       "0     allen-p/_sent_mail/1.  <18782981.1075855378110.JavaMail.evans@thyme>   \n",
       "1    allen-p/_sent_mail/10.  <15464986.1075855378456.JavaMail.evans@thyme>   \n",
       "2   allen-p/_sent_mail/100.  <24216240.1075855687451.JavaMail.evans@thyme>   \n",
       "3  allen-p/_sent_mail/1000.  <13505866.1075863688222.JavaMail.evans@thyme>   \n",
       "4  allen-p/_sent_mail/1001.  <30922949.1075863688243.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    Date                       From  \\\n",
       "0  Mon, 14 May 2001 16:39:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "1   Fri, 4 May 2001 13:51:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "2  Wed, 18 Oct 2000 03:00:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "3  Mon, 23 Oct 2000 06:13:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "4  Thu, 31 Aug 2000 05:07:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "\n",
       "                          To    Subject Mime-Version  \\\n",
       "0     (tim.belden@enron.com)                     1.0   \n",
       "1  (john.lavorato@enron.com)        Re:          1.0   \n",
       "2   (leah.arsdall@enron.com)   Re: test          1.0   \n",
       "3    (randall.gay@enron.com)                     1.0   \n",
       "4     (greg.piper@enron.com)  Re: Hello          1.0   \n",
       "\n",
       "                   Content-Type Content-Transfer-Encoding           X-From  \\\n",
       "0  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "1  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "2  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "3  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "4  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "\n",
       "                                                X-To X-cc X-bcc  \\\n",
       "0           Tim Belden <Tim Belden/Enron@EnronXGate>              \n",
       "1  John J Lavorato <John J Lavorato/ENRON@enronXg...              \n",
       "2                                   Leah Van Arsdall              \n",
       "3                                      Randall L Gay              \n",
       "4                                         Greg Piper              \n",
       "\n",
       "                                            X-Folder X-Origin  \\\n",
       "0  \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...  Allen-P   \n",
       "1  \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...  Allen-P   \n",
       "2    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail  Allen-P   \n",
       "3    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail  Allen-P   \n",
       "4    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail  Allen-P   \n",
       "\n",
       "                    X-FileName  \\\n",
       "0  pallen (Non-Privileged).pst   \n",
       "1  pallen (Non-Privileged).pst   \n",
       "2                   pallen.nsf   \n",
       "3                   pallen.nsf   \n",
       "4                   pallen.nsf   \n",
       "\n",
       "                                             content     user  \n",
       "0                          Here is our forecast\\n\\n   allen-p  \n",
       "1  Traveling to have a business meeting takes the...  allen-p  \n",
       "2                     test successful.  way to go!!!  allen-p  \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...  allen-p  \n",
       "4                Let's shoot for Tuesday at 11:45.    allen-p  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse the emails into a list email objects\n",
    "messages = list(map(email.message_from_string, emails_df['message']))\n",
    "emails_df.drop('message', axis=1, inplace=True)\n",
    "# Get fields from parsed email objects\n",
    "keys = messages[0].keys()\n",
    "for key in keys:\n",
    "    emails_df[key] = [doc[key] for doc in messages]\n",
    "# Parse content from emails\n",
    "emails_df['content'] = list(map(get_text_from_email, messages))\n",
    "# Split multiple email addresses\n",
    "emails_df['From'] = emails_df['From'].map(split_email_addresses)\n",
    "emails_df['To'] = emails_df['To'].map(split_email_addresses)\n",
    "\n",
    "# Extract the root of 'file' as 'user'\n",
    "emails_df['user'] = emails_df['file'].map(lambda x:x.split('/')[0])\n",
    "del messages\n",
    "\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index and drop columns with two few values\n",
    "emails_df = emails_df.set_index('Message-ID')\\\n",
    "    .drop(['file', 'Mime-Version', 'Content-Type', 'Content-Transfer-Encoding'], axis=1)\n",
    "# Parse datetimeq\n",
    "emails_df['Date'] = pd.to_datetime(emails_df['Date'], infer_datetime_format=True)\n",
    "emails_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic application of neural coref\n",
    "\n",
    "### Taking sample of 500 emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = []\n",
    "for x in range(len(emails_df[0:500])):\n",
    "    content_list.append(emails_df['content'][x])\n",
    "    \n",
    "doc_list = []\n",
    "for content in content_list:\n",
    "    doc_list.append(nlp(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at entity tags for those emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Many of the PERSON labels are just whitespace (e.g. \\r\\n\\r\\n). \n",
    "# Filter those out\n",
    "ents_tags = [(e.text.strip(), e.label_) for x in range(len(doc_list)) for e in doc_list[x].ents if e.text.strip()]\n",
    "\n",
    "persons = [e for e in ents_tags if e[1] == 'PERSON']\n",
    "\n",
    "person_counts = Counter(persons)\n",
    "\n",
    "person_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_people = []\n",
    "\n",
    "for person in persons:\n",
    "    if person[0] not in raw_people:\n",
    "        raw_people.append(person[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic functions to clean out some of the text in the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_people_list(people_list):\n",
    "    for x in range(len(people_list)):\n",
    "        people_list[x] = people_list[x].replace('ENRONDEVELOPMENT', '')\n",
    "        people_list[x] = people_list[x].replace('ENRON', '')\n",
    "        people_list[x] = people_list[x].replace('Contract', '')\n",
    "        people_list[x] = people_list[x].replace('Forward', '')\n",
    "        people_list[x] = people_list[x].replace('Accepted', '')\n",
    "        people_list[x] = people_list[x].replace('Login', '')\n",
    "        people_list[x] = people_list[x].replace('URGENT OWA', '')    \n",
    "        people_list[x] = re.sub(r'r?\\n|\\r/', '', people_list[x])\n",
    "        people_list[x] = re.sub(r'/[^/]*$', '', people_list[x])\n",
    "        people_list[x] = re.sub(r'/[^-]*$', '', people_list[x])\n",
    "        people_list[x] = re.sub(' +', ' ', people_list[x])\n",
    "        people_list[x] = re.sub(r'[^a-zA-Z ]+', '', people_list[x])\n",
    "        people_list[x] = people_list[x].strip()\n",
    "    return(people_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_people = clean_people_list(raw_people)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary where longest person name is the key and all variants that are components are values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_people_sorted = sorted(set(raw_people), key=len, reverse=True)\n",
    "\n",
    "people_dict = defaultdict(list)\n",
    "all_strings = []\n",
    "for person in raw_people_sorted[0:500]:\n",
    "    if not people_dict:\n",
    "        people_dict[person] = [person]\n",
    "    else:\n",
    "        keys = [i.split(' ') for i in list(people_dict.keys())]\n",
    "    if all([name in [item for sublist in keys for item in sublist] for name in person.split()]):\n",
    "        for key, value in people_dict.items():\n",
    "            if all([name in key.split() for name in person.split()]):\n",
    "                people_dict[key].append(person) \n",
    "    else:\n",
    "        people_dict[person] = [person]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this dict to enhance neural coref conversion dict definitions and re-process content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in people_dict.items():\n",
    "    nlp.get_pipe('neuralcoref').set_conv_dict({key: value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list2 = []\n",
    "for content in content_list:\n",
    "    doc_list2.append(nlp(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try limiting to emails with a 'PERSON' entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list = []\n",
    "for x in range(len(doc_list)):\n",
    "    for e in doc_list[x].ents:\n",
    "        if 'PERSON' in e.label_:\n",
    "            if x not in filtered_list:\n",
    "                filtered_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_docs = []\n",
    "for index in filtered_list:\n",
    "    filtered_docs.append(nlp(content_list[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_docs[134]._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_content_list = []\n",
    "for x in range(len(emails_df)):\n",
    "    content_list.append(emails_df['content'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = []\n",
    "for x in range(len(emails_df[0:500])):\n",
    "    content_list.append(emails_df['content'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_people = []\n",
    "for person in persons:\n",
    "    orig_people.append(person[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_people = clean_people_list(orig_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This doesn't work with 500 emails (at least on my machine)\n",
    "\n",
    "# content_blob = ' '.join(content_list)\n",
    "# processed_blob = nlp(content_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Reagan,\\n\\nThank you for the quick response on the bid for the residence.  Below is a \\nlist of questions on the specs:\\n\\n1.  Is the framing Lumber #2 yellow pine?  Wouldn't fir or spruce warp less \\nand cost about the same?\\n\\n2.  What type of floor joist would be used?  2x12 or some sort of factory \\njoist?\\n\\n3.  What type for roof framing?  On site built rafters? or engineered trusses?\\n\\n4.  Are you planning for insulation between floors to dampen sound?  What \\ntype of insulation in floors and ceiling?  Batts or blown?  Fiberglass or \\nCellulose?\\n\\n5.  Any ridge venting or other vents (power or turbine)?\\n\\n6. Did you bid for interior windows to have trim on 4 sides?  I didn't know \\nthe difference between an apron and a stool.\\n\\n7.  Do you do anything special under the upstairs tile floors to prevent \\ncracking?  Double plywood or hardi board underlay?\\n\\n8.  On the stairs, did you allow for a bannister?  I was thinking a partial \\none out of iron.  Only about 5 feet.\\n\\n9.  I did not label it on the plan, but I was intending for a 1/2 bath under \\nthe stairs. A pedestal sink would probably work.\\n\\n10.  Are undermount sinks different than drop ins?  I was thinking undermount \\nstainless in kitchen and undermount cast iron in baths.\\n\\n11.  1 or 2 A/C units?  I am assuming 2.\\n\\n12.  Prewired for sound indoors and outdoors?\\n\\n13.  No door and drawer pulls on any cabinets or just bath cabinets?\\n\\n14.  Exterior porches included in bid?  Cedar decking on upstairs?  Iron \\nrailings?\\n\\n15.  What type of construction contract would you use?  Fixed price except \\nfor change orders?\\n\\nI want to get painfully detailed with the specs before I make a decision but \\nthis is a start.  I think I am ready to get plans drawn up.  I am going to \\ncall Cary Kipp to\\nsee about setting up a design meeting to see if I like his ideas.\\n\\nPhillip\\nI\\n\\n \""
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(content_list) \n",
    "content_list.sort(key=len) \n",
    "content_list[length-60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'---------------------- Forwarded by Phillip K Allen/HOU/ECT on 08/20/2000 \\n05:38 PM ---------------------------\\n\\n\\n\"Lucy Gonzalez\" <stagecoachmama@hotmail.com> on 08/17/2000 02:37:55 PM\\nTo: pallen@enron.com\\ncc:  \\nSubject: Daily Report\\n\\n\\n\\n   Phillip,\\n        Today was one of those days because Wade had to go pay Wade fine and\\nI had to go take Wade that takes alot of time out of my schedule.If you get a\\nchance will you mention to Wade that Wade needs to, try to fix Wade van so tht\\nhis van can go get what ever his van needs. Tomorrow gary is going to be here.I have\\nto go but Iwill E-Mail you tomorrow\\n                                            Lucy\\n\\n________________________________________________________________________\\nGet Your Private, Free E-mail from MSN Hotmail at http://www.hotmail.com\\n\\n'"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list[length-121]._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cooper,\n",
       " \n",
       " Can you give access to the new west power site to Jay Reitmeyer.  He is an \n",
       "analyst in our group.\n",
       "\n",
       "Phillip"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cooper,\\n \\n Can you give access to the new west power site to Jay Reitmeyer.  Jay Reitmeyer is an \\nanalyst in our group.\\n\\nPhillip'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list[70]._.has_coref\n",
    "doc_list[70]._.coref_clusters\n",
    "doc_list[70]._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brad,\n",
       "\n",
       " With regard to Tori Kuykendall, I would like to promote her to commercial \n",
       "manager instead of converting her from a commercial support manager to an \n",
       "associate.  Her duties since the beginning of the year have been those of a \n",
       "commercial manager.  I have no doubt that she will compare favorably to \n",
       "others in that category at year end.  \n",
       "\n",
       " Martin Cuilla on the central desk is in a similiar situation as Tori.  \n",
       "Hunter would like Martin handled the same as Tori.\n",
       "\n",
       " Let me know if there are any issues.\n",
       "\n",
       "Phillip"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list[86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brad,\\n\\n With regard to Tori Kuykendall, I would like to promote Tori Kuykendall to commercial \\nmanager instead of converting Tori Kuykendall from a commercial support manager to an \\nassociate.  Tori Kuykendall duties since the beginning of the year have been those of a \\ncommercial manager.  I have no doubt that Tori Kuykendall will compare favorably to \\nothers in that category at year end.  \\n\\n Martin Cuilla on the central desk is in a similiar situation as Tori.  \\nHunter would like Martin Cuilla handled the same as Tori.\\n\\n Let me know if there are any issues.\\n\\nPhillip'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list[86]._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tori Kuykendall: [Tori Kuykendall, her, her, Her, she], Martin Cuilla: [Martin Cuilla, Martin]]\n",
      "[Tori Kuykendall: [Tori Kuykendall, her, her, Her, she], Martin Cuilla: [Martin Cuilla, Martin]]\n"
     ]
    }
   ],
   "source": [
    "# doc_list[86]._.has_coref\n",
    "# doc_list[86]._.coref_clusters\n",
    "print(doc_list[86]._.coref_clusters)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tori Kuykendall: [Tori Kuykendall, her, her, Her, she],\n",
       " Martin Cuilla: [Martin Cuilla, Martin]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc_list[86]._.has_coref\n",
    "doc_list[86]._.coref_clusters\n",
    "# doc_list[86]._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolved_list = []\n",
    "for x in range(len(doc_list)):\n",
    "    resolved_list.append(nlp(doc_list[x]._.coref_resolved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Phillip K Allen', 'PERSON'), 312),\n",
       " (('Phillip Allen', 'PERSON'), 70),\n",
       " (('Lucy', 'PERSON'), 48),\n",
       " (('Keith', 'PERSON'), 40),\n",
       " (('Jeff', 'PERSON'), 36),\n",
       " (('Keith Holst', 'PERSON'), 26),\n",
       " (('Phillip', 'PERSON'), 26),\n",
       " (('John', 'PERSON'), 26),\n",
       " (('Larry Lewter', 'PERSON'), 24),\n",
       " (('Reagan', 'PERSON'), 23),\n",
       " (('Larry', 'PERSON'), 23),\n",
       " (('Tim Belden', 'PERSON'), 22),\n",
       " (('George', 'PERSON'), 21),\n",
       " (('Mike Grigsby', 'PERSON'), 20),\n",
       " (('Alan Comnes', 'PERSON'), 18),\n",
       " (('George Richards', 'PERSON'), 17),\n",
       " (('Scott Neal', 'PERSON'), 17),\n",
       " (('Creekside Builders', 'PERSON'), 16),\n",
       " (('Mike', 'PERSON'), 16),\n",
       " (('Gary', 'PERSON'), 16)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents_tags_resolved = [(e.text.strip(), e.label_) for x in range(len(resolved_list)) for e in resolved_list[x].ents if e.text.strip()]\n",
    "\n",
    "persons_resolved = [e for e in ents_tags_resolved if e[1] == 'PERSON']\n",
    "\n",
    "person_counts_resolved = Counter(persons_resolved)\n",
    "\n",
    "person_counts_resolved.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    stop = set(stopwords.words('english'))\n",
    "    stop.update((\"to\",\"cc\",\"subject\",\"http\",\"from\",\"sent\",\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"))\n",
    "    exclude = set(string.punctuation) \n",
    "    lemma = WordNetLemmatizer()\n",
    "    porter= PorterStemmer()\n",
    "    \n",
    "    text=text.rstrip()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    stop_free = \" \".join([i for i in text.lower().split() if((i not in stop) and (not i.isdigit()))])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    #stem = \" \".join(porter.stem(token) for token in normalized.split())\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df=emails_df[['From', 'To', 'Date','content']].dropna().copy()\n",
    "analysis_df = analysis_df.loc[analysis_df['To'].map(len) == 1]\n",
    "sub_df=analysis_df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_df[\"content\"]=sub_df[\"content\"].map(clean)\n",
    "text_clean=[]\n",
    "for text in sub_df['content']:\n",
    "    text_clean.append(clean(text).split())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
